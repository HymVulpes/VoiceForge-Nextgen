# VoiceForge-Nextgen V2 (RAM-Optimized)

**Real-time Voice Conversion with 24GB RAM Optimization**

Priority: **Correctness â†’ Stability â†’ Performance â†’ Debug**

---

## ğŸš€ What's New in V2

### **RAM Optimization (24GB)**
- **2GB** Pre-allocated buffer pool (1000 slots)
- **8GB** Multi-model hot cache (40-160 models)
- **4GB** Feature cache (F0, HuBERT)
- **Zero dynamic allocation** during runtime
- **Lock-free** triple buffering
- **Zero-copy** audio path where possible

### **Correctness First**
- âœ… All operations validated before execution
- âœ… Contract-based validation (shape, dtype, range)
- âœ… Integrity checks every 60 seconds
- âœ… No silent failures (all errors logged)

### **Enhanced Stability**
- âœ… State machine with validated transitions
- âœ… Automatic failsafe mode on errors
- âœ… Graceful degradation (never crash)
- âœ… Self-healing (auto-recovery)

### **Performance Improvements**
- âœ… Pre-allocated buffers (no GC pauses)
- âœ… Lock-free communication
- âœ… Model hot-swapping (zero latency)
- âœ… Predictive feature caching

---

## ğŸ“Š Memory Allocation (24GB System)

```
Total: 24GB
â”œâ”€â”€ System/Windows: 4GB     (Reserved)
â”œâ”€â”€ Audio Buffers: 2GB      (100 slots Ã— 10 sec @ 48kHz)
â”œâ”€â”€ Model Cache: 8GB        (40-160 RVC models)
â”œâ”€â”€ Feature Cache: 4GB      (400-4000 feature sets)
â”œâ”€â”€ Working Memory: 4GB     (Processing, GPU)
â””â”€â”€ Safety Margin: 2GB      (Emergency headroom)
```

---

## ğŸ—ï¸ New Architecture

### **V1 vs V2 Comparison**

| Component | V1 (Dynamic) | V2 (Pre-allocated) |
|-----------|--------------|-------------------|
| Audio buffers | Ring buffer (dynamic) | Pre-allocated pool |
| Model loading | Load on demand | Hot cache (8GB) |
| Features | Extract every time | Cached (4GB) |
| Communication | Locks | Lock-free triple buffer |
| Latency | ~18ms | ~12ms (target) |
| Stability | Good | Excellent |

### **Lock-Free Triple Buffering**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WRITE Bufferâ”‚ â† Audio callback writes here
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“ Swap when full
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SWAP Buffer â”‚ â† Ready to swap
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“ Atomic swap
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ READ Buffer â”‚ â† Inference reads here
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Advantages**:
- No locks (no deadlocks)
- No torn reads/writes
- Constant-time operations
- Perfect for realtime audio

---

## ğŸ”§ Installation (V2 Specific)

### **Prerequisites**

**Critical**: 
- **20GB+ RAM** (24GB recommended)
- **NVIDIA GPU** with 6GB+ VRAM (for 8GB model cache)
- **50GB+ free disk** (for logs, snapshots, models)

### **Step 1: Verify System Resources**

```bash
# Check RAM
wmic memorychip get capacity
# Should show 24GB+

# Check GPU VRAM
nvidia-smi
# Should show 6GB+ VRAM
```

### **Step 2: Install (Same as V1)**

```bash
cd D:\Coding\Project Voice\VoiceForge-Nextgen
setup.bat
```

### **Step 3: Configure Memory Limits**

Edit `config.yaml`:

```yaml
resources:
  total_ram_gb: 24  # Adjust to your system
  allocation:
    model_cache_gb: 8    # Reduce if < 24GB RAM
    feature_cache_gb: 4  # Reduce if < 24GB RAM
```

### **Step 4: Run Diagnostic**

```bash
python diagnostic_tool.py
```

**New checks in V2**:
- âœ… RAM availability (need 10GB+ free)
- âœ… Disk space (need 5GB+ free)
- âœ… Buffer pool pre-allocation test
- âœ… Cache integrity test

---

## ğŸ¯ Running V2

### **Golden Path (No AI)**

```bash
python app/main_v2.py
```

**Expected output**:
```
VoiceForge-Nextgen V2 (RAM-Optimized)
Priority: Correctness â†’ Stability â†’ Performance â†’ Debug
====================================================================
Checking system resources...
System RAM: 24.0GB total, 18.2GB available
âœ“ Resources adequate

Pre-allocating buffer pool (2GB)...
Buffer pool allocated: 2.00 GB
âœ“ Buffer pool integrity OK

Initializing model cache (8GB)...
Initializing feature cache (4GB)...
âœ“ All initialization checks passed

Starting GOLDEN PATH mode (no AI processing)
âœ“ Golden Path ACTIVE
Speak into microphone - audio should route to Virtual Audio Cable
```

### **Monitoring Output**

Every 5 seconds:
```
------------------------------------------------------------
Audio Stream: state=running, in_callbacks=1024, out_writes=1024, errors=0
Buffer Pool: 5/100 (5.0%), max_usage=8
Model Cache: 0 models, 0.00GB/8.00GB
Feature Cache: 0 entries, hit_rate=0.0%
CPU: 12.5% | RAM: 8450MB (35.2%)
GPU: NVIDIA GeForce RTX 4070 | VRAM: 128MB
------------------------------------------------------------
```

---

## ğŸ” Correctness Guarantees

### **1. Contract Validation**

All audio data validated:
```python
# Example validation
if audio_data.dtype != np.float32:
    logger.error("Invalid dtype")
    # Convert or reject

if not np.isfinite(audio_data).all():
    logger.error("Non-finite values detected")
    audio_data = np.nan_to_num(audio_data)
```

### **2. State Machine**

Only valid transitions allowed:
```
STOPPED â†’ STARTING â†’ RUNNING
    â†“         â†“         â†“
 FAILED â† FAILSAFE â† STOPPING
```

Invalid transitions rejected:
```
RUNNING â†’ STOPPED  âŒ (must go through STOPPING)
STOPPED â†’ FAILSAFE âŒ (not reachable)
```

### **3. Integrity Checks**

Every 60 seconds:
- Buffer pool: no double-frees, no corruption
- Audio stream: state consistency
- Cache: no memory leaks

### **4. Snapshot on Failure**

Any error â†’ automatic snapshot:
```
logs/snapshots/
  â””â”€â”€ snapshot_abc12345_ERROR_INFERENCE/
      â”œâ”€â”€ metadata.json
      â”œâ”€â”€ audio_input.npy    # Exact input that caused error
      â”œâ”€â”€ audio_output.npy   # Output if any
      â””â”€â”€ system_state.json  # Full system state
```

---

## âš¡ Performance Optimizations

### **1. Zero-Copy Audio Path**

V1 (Copy):
```
Mic â†’ Buffer â†’ Copy â†’ Process â†’ Copy â†’ VAC
```

V2 (Zero-copy):
```
Mic â†’ Pre-allocated slot â†’ Process in-place â†’ VAC
```

### **2. Model Hot-Swapping**

V1:
```
Load model (500ms) â†’ Inference (15ms)
Total: 515ms per model switch
```

V2:
```
Model already in cache â†’ Inference (15ms)
Total: 15ms (97% faster)
```

### **3. Feature Caching**

V1:
```
Extract F0 (10ms) + HuBERT (8ms) = 18ms per chunk
```

V2 (cache hit):
```
Lookup cached features (0.01ms)
Total: 99.9% faster
```

### **4. Latency Breakdown**

| Stage | V1 | V2 (Target) |
|-------|-------|-------------|
| Input | 2.3ms | 1.8ms |
| Preprocess | 1.2ms | 0.5ms |
| Inference | 12.1ms | 8.0ms |
| Postprocess | 0.8ms | 0.3ms |
| Output | 2.1ms | 1.4ms |
| **Total** | **18.5ms** | **12.0ms** |

---

## ğŸ›¡ï¸ Stability Features

### **1. Failsafe Mode**

Automatic activation on:
- 5 consecutive errors
- Buffer pool corruption
- Device failure
- Inference timeout

**Behavior**: Direct mic â†’ VAC passthrough (no AI)

### **2. Graceful Degradation**

Priority cascade:
1. Try full AI pipeline
2. If fails â†’ Try cached features
3. If fails â†’ Passthrough audio
4. Never crash

### **3. Self-Healing**

Auto-recovery after 2 seconds:
```
Error â†’ Failsafe â†’ Wait 2s â†’ Retry AI
```

### **4. Resource Monitoring**

Auto-evict if:
- RAM > 85% (evict LRU model)
- GPU VRAM > 90% (evict LRU features)
- CPU > 80% (reduce buffer size)

---

## ğŸ“ Configuration (config.yaml)

### **Critical Settings**

```yaml
resources:
  total_ram_gb: 24          # MUST match your system
  allocation:
    audio_buffers_gb: 2     # Buffer pool size
    model_cache_gb: 8       # Model cache
    feature_cache_gb: 4     # Feature cache

audio:
  buffer_size: 256          # Lower = less latency, less stable
  validate_devices_on_startup: true

processing:
  failsafe:
    max_consecutive_errors: 5
    auto_recover: true
    
debug:
  snapshots:
    on_error: true          # Always capture errors
    on_latency_spike: true  # Capture if > 40ms
```

---

## ğŸ› Debugging V2

### **1. Check Buffer Pool Integrity**

```python
from app.audio.buffer_pool import BufferPool

pool = BufferPool(...)
assert pool.validate_integrity()  # Should never fail
```

### **2. Analyze Snapshots**

```python
import json
import numpy as np

# Load snapshot
metadata = json.load(open('metadata.json'))

# Check buffer pool state
pool_stats = metadata['additional_data']['buffer_pool']
print(f"Free slots: {pool_stats['free']}/{pool_stats['total_slots']}")

# Check audio
audio = np.load('audio_input.npy')
print(f"RMS: {np.sqrt(np.mean(audio**2))}")
```

### **3. Monitor Cache Performance**

Check logs for:
```
Model Cache: hit_rate=95.2% (excellent)
Feature Cache: hit_rate=87.3% (good)
```

Low hit rate â†’ increase cache size in config.yaml

---

## ğŸš¨ Troubleshooting V2

### **"Buffer pool exhausted"**

**Cause**: Too many buffers in use

**Solution**:
1. Increase `num_slots` in config
2. Check for buffer leaks (integrity check)
3. Reduce processing latency

### **"Integrity check failed"**

**Cause**: Memory corruption detected

**Solution**:
1. Check logs for details
2. Snapshot captured automatically
3. Restart application
4. Report bug with snapshot

### **High memory usage**

**Cause**: Caches too large for system

**Solution**: Edit `config.yaml`:
```yaml
cache:
  model_cache:
    max_size_gb: 4  # Reduce from 8
  feature_cache:
    max_size_gb: 2  # Reduce from 4
```

### **Failsafe keeps activating**

**Cause**: AI processing unstable

**Solution**:
1. Check GPU drivers
2. Reduce inference timeout
3. Enable debug logging
4. Check snapshots for errors

---

## ğŸ“ˆ Performance Tuning

### **For Maximum Speed (Sacrifices Stability)**

```yaml
audio:
  buffer_size: 128           # Lower latency

processing:
  failsafe:
    max_consecutive_errors: 10  # More tolerance
```

### **For Maximum Stability (Sacrifices Speed)**

```yaml
audio:
  buffer_size: 512           # Higher latency

processing:
  latency:
    critical_threshold_ms: 100.0  # More tolerance
    
  failsafe:
    max_consecutive_errors: 3     # Fast failsafe
```

---

## ğŸ“ Best Practices

### **DO**
- âœ… Run diagnostic before each session
- âœ… Monitor logs during first runs
- âœ… Keep 10GB+ RAM free
- âœ… Check snapshots after errors
- âœ… Validate buffer pool periodically

### **DON'T**
- âŒ Modify buffer pool during runtime
- âŒ Disable integrity checks
- âŒ Ignore failsafe warnings
- âŒ Run with < 16GB RAM
- âŒ Skip device validation

---

## ğŸ“Š Success Metrics

**V2 is working correctly if**:
- âœ… Golden Path runs without errors
- âœ… Buffer pool integrity always passes
- âœ… No failsafe activations in Golden Path
- âœ… Memory usage stable over time
- âœ… Cache hit rates > 80%

---

**V2 Changes Summary**:
- âœ… 2GB pre-allocated buffers
- âœ… 8GB model hot cache
- âœ… 4GB feature cache
- âœ… Lock-free triple buffering
- âœ… Comprehensive validation
- âœ… Auto-failsafe
- âœ… Self-healing
- âœ… Full observability

**Priority maintained**: Correctness â†’ Stability â†’ Performance â†’ Debug